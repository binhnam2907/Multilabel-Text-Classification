{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import các thư viện cần thiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Tiền xử lý**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english') # Lấy danh sách stopwords từ thư viện ntlk\n",
    "stemmer = PorterStemmer() # Khai báo stemmer object (dùng để stemming trong hàm normalize text)\n",
    "\n",
    "# Xây dựng hàm text normalization\n",
    "def text_normalize(text):\n",
    "    text = text.lower() # Chuyển chữ viết thường \n",
    "    text = unidecode.unidecode(text) # Mã hóa về ASCII\n",
    "    text = text.strip() # Xóa kí tự đặc biệt ở đầu và cuối string\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Loại bỏ dấu câu\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in english_stop_words]) # Xóa stopwords\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split(' ')]) # Stemming\n",
    " \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 128\n",
    "MAX_FEATURES = 5000 \n",
    "EMBEDDING_DIMS = 64\n",
    "\n",
    "train_filepath = \"dataset/train.csv\"\n",
    "val_filepath = \"dataset/val.csv\"\n",
    "test_filepath = \"dataset/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_filepath, \n",
    "                index_col=0) \n",
    "val_df = pd.read_csv(val_filepath, \n",
    "                index_col=0) \n",
    "test_df = pd.read_csv(test_filepath, \n",
    "                index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tweet'] = train_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n",
    "val_df['Tweet'] = val_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n",
    "test_df['Tweet'] = test_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n",
    "\n",
    "class_lst = np.array(train_df.columns[2:])\n",
    "n_classes = len(class_lst)\n",
    "\n",
    "X_train, y_train = train_df['Tweet'].to_numpy(), train_df[class_lst].astype('int').to_numpy()\n",
    "X_val, y_val = val_df['Tweet'].to_numpy(), val_df[class_lst].astype('int').to_numpy()\n",
    "X_test, y_test = test_df['Tweet'].to_numpy(), test_df[class_lst].astype('int').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-21441</td>\n",
       "      <td>worri payment problem may never  joyc meyer  m...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-31535</td>\n",
       "      <td>whatev decid make sure make happi</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-En-21068</td>\n",
       "      <td>max_kellerman  also help major nfl coach inept...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  anger  \\\n",
       "0  2017-En-21441  worri payment problem may never  joyc meyer  m...  False   \n",
       "1  2017-En-31535                  whatev decid make sure make happi  False   \n",
       "2  2017-En-21068  max_kellerman  also help major nfl coach inept...   True   \n",
       "\n",
       "   anticipation  disgust   fear    joy   love  optimism  pessimism  sadness  \\\n",
       "0          True    False  False  False  False      True      False    False   \n",
       "1         False    False  False   True   True      True      False    False   \n",
       "2         False     True  False   True  False      True      False    False   \n",
       "\n",
       "   surprise  trust  \n",
       "0     False   True  \n",
       "1     False  False  \n",
       "2     False  False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0:  b'worri payment problem may never  joyc meyer  motiv leadership worri'\n",
      "Label: ['anticipation' 'optimism' 'trust']\n",
      "Tweet 1:  b'whatev decid make sure make happi'\n",
      "Label: ['joy' 'love' 'optimism']\n",
      "Tweet 2:  b'max_kellerman  also help major nfl coach inept bill obrien play call wow  gopat'\n",
      "Label: ['anger' 'disgust' 'joy' 'optimism']\n",
      "Tweet 3:  b'accept challeng liter even feel exhilar victori  georg patton'\n",
      "Label: ['joy' 'optimism']\n",
      "Tweet 4:  b'roommat okay cant spell autocorrect terribl firstworldprob'\n",
      "Label: ['anger' 'disgust']\n",
      "Tweet 5:  b'that cute atsu probabl shi photo cherri help uwu'\n",
      "Label: ['joy']\n",
      "Tweet 6:  b'think human sens recogn impend doom'\n",
      "Label: ['anticipation' 'pessimism']\n",
      "Tweet 7:  b'rooney fuck untouch isnt fuck dread depay look decentishtonight'\n",
      "Label: ['anger' 'disgust']\n",
      "Tweet 8:  b'pretti depress u hit pan ur favourit highlight'\n",
      "Label: ['disgust' 'sadness']\n",
      "Tweet 9:  b'bossupjae pussi weak heard stfu bitch  got threaten pregnant '\n",
      "Label: ['anger' 'disgust']\n"
     ]
    }
   ],
   "source": [
    "def inverse_label(class_lst, onehot_label):\n",
    "    return class_lst[onehot_label > 0]\n",
    "\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(10):\n",
    "    print(f\"Tweet {i}: \", text_batch.numpy()[i])\n",
    "    print(\"Label:\", inverse_label(class_lst, label_batch.numpy()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình các tham số tối ưu cho việc đọc dữ liệu\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Xây dựng mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo layer text vectorization\n",
    "text_vectorization_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=MAX_FEATURES, # Kích thước bộ từ vựng\n",
    "    output_mode='int', # Giá trị token là chỉ mục của từ trong vocab\n",
    "    output_sequence_length=MAX_SEQ_LEN # Số token tối đa trong 1 vector\n",
    ")\n",
    "\n",
    "train_text = train_ds.map(lambda text, labels: text) # Gọi `content` của toàn bộ mẫu dữ liệu trong tập train\n",
    "text_vectorization_layer.adapt(train_text) # Xây dựng layer vectorization dựa trên dữ liệu tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng hàm khởi tạo model\n",
    "def build_model(max_features, max_seq_len, embedding_dims, n_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input layer (nhận vào 1 string)\n",
    "        tf.keras.Input(shape=(1,), dtype='string', name='input_layer'), \n",
    "\n",
    "        # Text Vectorization Layer đã khai báo ở trên\n",
    "        text_vectorization_layer, \n",
    "\n",
    "        # Embedding Layer (chuyển đổi các token thành các vector)\n",
    "        tf.keras.layers.Embedding(input_dim=max_features+1, \n",
    "                                  output_dim=embedding_dims, \n",
    "                                  embeddings_initializer=tf.random_uniform_initializer(),\n",
    "                                  mask_zero=True,\n",
    "                                  name='embedding_layer'), \n",
    "\n",
    "        # Bi-LSTM Layer 1 \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, \n",
    "                                    return_sequences=True, \n",
    "                                    kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "                                    name='bilstm_layer_1'),\n",
    "        # Bi-LSTM Layer 2\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, \n",
    "                                    return_sequences=True, \n",
    "                                    kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "                                    name='bilstm_layer_2'),\n",
    "        # Bi-LSTM Layer 3\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, \n",
    "                                    return_sequences=False, \n",
    "                                    kernel_initializer=tf.initializers.GlorotUniform()),\n",
    "                                    name='bilstm_layer_3'),\n",
    "                                 \n",
    "        # Dropout Layer 1\n",
    "        tf.keras.layers.Dropout(0.2,\n",
    "                                name='dropout_layer_1'),\n",
    "\n",
    "        # Fully-connected Layer 1\n",
    "        tf.keras.layers.Dense(64, \n",
    "                              activation='relu',\n",
    "                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                              name='fc_layer_1'),\n",
    "\n",
    "        # Dropout Layer 2\n",
    "        tf.keras.layers.Dropout(0.3,\n",
    "                                name='dropout_layer_2'),\n",
    "\n",
    "        # Fully-connected Layer 2\n",
    "        tf.keras.layers.Dense(32, \n",
    "                              activation='relu',\n",
    "                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                              name='fc_layer_2'),\n",
    "\n",
    "        # Dropout Layer 3\n",
    "        tf.keras.layers.Dropout(0.3,\n",
    "                                name='dropout_layer_3'),\n",
    "\n",
    "        # Output Layer\n",
    "        tf.keras.layers.Dense(n_classes, \n",
    "                              activation='sigmoid', \n",
    "                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                              name='output_layer') \n",
    "    ],\n",
    "    name='bilstm_model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bilstm_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 128)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 128, 64)          320064    \n",
      "                                                                 \n",
      " bilstm_layer_1 (Bidirection  (None, 128, 128)         66048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bilstm_layer_2 (Bidirection  (None, 128, 128)         98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bilstm_layer_3 (Bidirection  (None, 128)              98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout_layer_1 (Dropout)   (None, 128)               0         \n",
      "                                                                 \n",
      " fc_layer_1 (Dense)          (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_layer_2 (Dropout)   (None, 64)                0         \n",
      "                                                                 \n",
      " fc_layer_2 (Dense)          (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_layer_3 (Dropout)   (None, 32)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,443\n",
      "Trainable params: 594,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(max_features=MAX_FEATURES, \n",
    "                    max_seq_len=MAX_SEQ_LEN,\n",
    "                    embedding_dims=EMBEDDING_DIMS, \n",
    "                    n_classes=n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Cấu hình mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo một số giá trị siêu tham số\n",
    "EPOCHS = 30\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR), # Sử dụng optimizer Adam\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), # Sử dụng hàm loss BinaryCrossEntropy\n",
    "    metrics=['accuracy'] # Sử dụng thêm độ đo đánh giá Accuracy\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Thực hiện huấn luyện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thực hiện huấn luyện\n",
    "history = model.fit( \n",
    "    train_ds, # Huấn luyện với bộ train_ds\n",
    "    validation_data=val_ds, # Đánh giá trên bộ val_ds\n",
    "    epochs=EPOCHS # Huấn luyện với số lần lặp = số epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Đánh giá và trực quan hóa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tập test\n",
    "test_evaluation = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc các kết quả huấn luyện mô hình qua từng epoch\n",
    "train_loss, train_acc = history.history['loss'], history.history['accuracy'] # Đọc thông tin loss, acc trên tập train\n",
    "val_loss, val_acc = history.history['val_loss'], history.history['val_accuracy'] # Đọc thông tin loss, acc trên tập val\n",
    "\n",
    "plt.figure(figsize=(10, 10)) # Cài đặt kích thước khung ảnh\n",
    "\n",
    "plt.subplot(2, 2, 1) # Khởi tạo khung ảnh cho training loss\n",
    "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
    "plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n",
    "plt.title('Training loss') # Hiển thị title của khung ảnh hiện tại là 'Training Loss'\n",
    "plt.plot(train_loss, color='green') # Vẽ đường giá trị loss trên tập train qua từng epoch (đường vẽ màu đỏ)\n",
    "\n",
    "plt.subplot(2, 2, 2) # Khởi tạo khung ảnh cho training acc\n",
    "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
    "plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n",
    "plt.title('Training accuracy') # Hiển thị title của khung ảnh hiện tại là 'Training accuracy'\n",
    "plt.plot(train_acc, color='orange') # Vẽ đường giá trị accuracy trên tập train qua từng epoch (đường vẽ màu cam)\n",
    "\n",
    "plt.subplot(2, 2, 3) # Khởi tạo khung ảnh cho val loss\n",
    "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
    "plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n",
    "plt.title('Validation loss') # Hiển thị title của khung ảnh hiện tại là 'Validation loss'\n",
    "plt.plot(val_loss, color='green') # Vẽ đường giá trị loss trên tập val qua từng epoch (đường vẽ màu đỏ)\n",
    "\n",
    "plt.subplot(2, 2, 4) # Khởi tạo khung ảnh cho val acc\n",
    "plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n",
    "plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n",
    "plt.title('Validation accuracy') # Hiển thị title của khung ảnh hiện tại là 'Validation accuracy'\n",
    "plt.plot(val_acc, color='orange') # Vẽ đường giá trị accuracy trên tập val qua từng epoch (đường vẽ màu cam)\n",
    "\n",
    "plt.show() # Hiển thị 4 khung ảnh nhỏ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "for text_batch, label_batch in test_ds.take(1):\n",
    "    for i in range(10):\n",
    "        input_text = text_batch[i].numpy()\n",
    "        label = label_batch[i].numpy()\n",
    "        pred = model.predict(np.expand_dims(input_text, 0), verbose=0)[0]\n",
    "        threshold_pred = np.where(pred > threshold, 1, 0)\n",
    "        print(f\"Text: {input_text}\")\n",
    "        print(f\"Label: {inverse_label(class_lst, label)}\")\n",
    "        print(f\"Predicted Label(s): ({inverse_label(class_lst, threshold_pred)})\")\n",
    "        print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
